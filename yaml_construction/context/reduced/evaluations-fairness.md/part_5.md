**Do the math** : The following formula is used for calculating the false omission rate (FOR): false negatives False omission rate = ________________________________________ true negatives + false negatives Copy to clipboard The following formula is used for the false omission rate difference: False omission rate difference = FOR of monitored group - FOR of reference group Copy to clipboard ## Error rate difference[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#error-rate-difference "Copy to clipboard") The error rate difference calculates the percentage of transactions that are incorrectly scored by your model. * **Description** : Returns the difference in error rate for the monitored and reference groups. * **At 0** : Both groups have equal odds. * **Uses the confusion matrix to measure performance** : Yes * **Do the math** : The following formula is used for calculating the the error rate (ER): false positives + false negatives Error rate = ___________________________________________ all positives + all negatives Copy to clipboard The following formula is used for calculating the error rate difference: Error rate difference = ER of monitored group - ER of reference group Copy to clipboard ## Average odds difference[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#average-odds-difference "Copy to clipboard") The average odds difference gives the percentage of transactions that was incorrectly scored by your model. * **Description** : Returns the difference in error rate for the monitored and reference groups. * **At 0** : Both groups have equal odds. * **Uses the confusion matrix to measure performance** : Yes * **Do the math** : The following formula is used for calculating false positive rate (FPR): false positives False positive rate = _________________________ total negatives Copy to clipboard The following formula is used for calculating true positive rate (TPR): True positives True positive rate = ______________________ All positives Copy to clipboard The following formula is used for calculating average odds difference: (FPR monitored group - FPR reference group) + (TPR monitored group - TPR reference group) Average odds difference = ___________________________________________________________________________________________ 2 Copy to clipboard ## Average absolute odds difference[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#average-absolute-odds-difference "Copy to clipboard") The average absolute odds difference compares the average of absolute difference in false positive rates and true positive rates between monitored groups and reference groups. * **Description** : Returns the average of the absolute difference in false positive rate and true positive rate for the monitored and reference groups. * **At 0** : Both groups have equal odds. * **Uses the confusion matrix to measure performance** : Yes * **Do the math** : The following formula is used for calculating false positive rate (FPR): false positives False positive rate = ____________________________ all negatives Copy to clipboard The following formula is used for calculating true positive rate (TPR): True positives True positive rate = ________________________ All positives Copy to clipboard The following formula is used for calculating average absolute odds difference: |FPR monitored group - FPR reference group| + |TPR monitored group - TPR reference group| Average absolute odds difference = ______________________________________________________________________________________________ 2 Copy to clipboard ### Measure Performance with Confusion Matrix[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#performance_measures "Copy to clipboard") The confusion matrix measures performance categorizes positive and negative
your fairness evaluations on the Watson OpenScale Insights dashboard. For more information, see [Reviewing fairness results](/docs/en/SSQNUZ_5.0.x/wsj/model/wos-insight-timechart.html#analyze-fairness). The following metrics are supported by fairness evaluations: ## Disparate impact[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#disparate-impact "Copy to clipboard") Disparate impact is specified as the fairness scores for different groups. Disparate impact compares the percentage of favorable outcomes for a monitored group to the percentage of favorable outcomes for a reference group. * **How it works:** When you view the details of a model deployment, the **Fairness** section of the model summary that is displayed, provides the fairness scores for different groups that are described as metrics. The fairness scores are calculated with the disparate impact formula. * **Uses the confusion matrix to measure performance** : No * **Do the math:** (num_positives(privileged=False) / num_instances(privileged=False)) Disparate impact = ______________________________________________________________________ (num_positives(privileged=True) / num_instances(privileged=True)) Copy to clipboard The `num_positives` value represents the number of individuals in the group who received a positive outcome, and the `num_instances` value represents the total number of individuals in the group. The `privileged=False` label specifies unprivileged groups and the `privileged=True` label specifies privileged groups. The positive outcomes are designated as the favorable outcomes, and the negative outcomes are designated as the unfavorable outcomes. The privileged group is designated as the reference group, and the unprivileged group is designated as the monitored group. The calculation produces a percentage that specifies how often the rate that the unprivileged group receives the positive outcome is the same rate that the privileged group receives the positive outcome. For example, if a credit risk model assigns the “no risk” prediction to 80% of unprivileged applicants and to 100% of privileged applicants, that model has a disparate impact of 80%. * **Supported fairness details** * Watson OpenScale supports the following details for fairness metrics: * The favorable percentages for each of the groups * Fairness averages for all the fairness groups * Distribution of the data for each of the monitored groups * Distribution of payload data ## Statistical parity difference[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#statistical-parity-difference "Copy to clipboard") The statistical parity difference compares the percentage of favorable outcomes for monitored groups to reference groups. * **Description** : Fairness metric that describes the fairness for the model predictions. It is the difference between the ratio of favorable outcomes in monitored and reference groups * **Under 0** : Higher benefits for the monitored group. * **At 0** : Both groups have equal benefit. * **Over 0** Implies higher benefit for the reference group. * **Uses the confusion matrix to measure performance** : Yes * **Do the math** : num_positives(privileged=False) num_positives(privileged=True) Statistical parity difference = ________________________________ - ________________________________ num_instances(privileged=False) num_instances(privileged=True) Copy to clipboard ## Impact score[](/docs/en/cloud-paks/cp-data/5.0.x?topic=evaluations-fairness#impact-score "Copy to clipboard") The impact score compares the rate that monitored groups are selected to receive favorable outcomes to the rate that reference groups are selected to receive favorable outcomes. * **Do the math** : The following formula calculates the selection rate for each group: number of individuals receiving favorable outcomes Selection rate = ________________________________________________________ total number of individuals Copy to clipboard The following